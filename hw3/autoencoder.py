from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, UpSampling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import SGD, Adam
from keras.models import Model
import pickle
import numpy as np
import sys

def data_split(X_train, nVali):
    Xlen = len(X_train)
    Xshape = (Xlen - nVali, 3, 32, 32)
    xs = np.random.permutation(np.arange(len(X_train)))[:nVali]
    newX_train = np.zeros(Xshape, np.dtype('float32'))
    valiXShape = (nVali, 3, 32, 32)
    ValiX = np.zeros(valiXShape, np.dtype('float32'))
    check = np.zeros((len(X_train)), np.dtype(bool))
    for x in xs:
        check[x] = 1
    count = 0
    countValData = 0
    for j in range(len(check)):
        if check[j] == False:
            newX_train[count] = X_train[j]
            count += 1
        else:
            ValiX[countValData] = X_train[j]
            countValData += 1
    return (newX_train, ValiX)
label = pickle.load(open( sys.argv[1] + 'all_label.p','rb'))
label = np.array(label)
label = label.reshape(5000,3,32,32)
unlabel = pickle.load(open( sys.argv[1] + 'all_unlabel.p','rb'))
unlabel = np.array(unlabel)
unlabel = np.reshape(unlabel,(45000,3,32,32))
test = pickle.load(open( sys.argv[1] + 'test.p','rb'))
test = np.reshape(test['data'],(10000,3,32,32))
test = test.astype('float32')
X_train = np.concatenate((label,unlabel,test))
X_train = X_train.reshape(60000,3,32,32)
X_train = X_train.astype('float32')
X_train /= 255

input_img = Input(shape=(3, 32, 32))

x = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(input_img)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x)
x = MaxPooling2D((2, 2), border_mode='same')(x)
x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(x)
encoded = MaxPooling2D((2, 2), border_mode='same')(x)

# at this point the representation is (8, 4, 4) i.e. 128-dimensional

x = Convolution2D(8, 3, 3, activation='relu', border_mode='same')(encoded)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(16, 3, 3, activation='relu', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
x = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)
x = UpSampling2D((2, 2))(x)
decoded = Convolution2D(3, 3, 3, activation='sigmoid', border_mode='same')(x)

autoencoder = Model(input_img, decoded)
encoder = Model(input_img, output=encoded)
autoencoder.compile(optimizer=Adam(), loss='binary_crossentropy')
print('Using real-time data augmentation.')
# this will do preprocessing and realtime data augmentation
datagen = ImageDataGenerator(
                                featurewise_center=False,  # set input mean to 0 over the dataset
                                samplewise_center=False,  # set each sample mean to 0
                                featurewise_std_normalization=False,  # divide inputs by std of the dataset
                                samplewise_std_normalization=False,  # divide each input by its std
                                zca_whitening=False,  # apply ZCA whitening
                                rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)
                                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
                                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
                                horizontal_flip=True,  # randomly flip images
                                vertical_flip=False)  # randomly flip images

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
#datagen.fit(X_train)
History = []
for i in range(10):
    for X_batch, Y_batch in datagen.flow(X_train, X_train, batch_size=20000):
        x_train = X_batch
        break
# fit the model on the batches generated by datagen.flow()
    history = autoencoder.fit(x_train, x_train, nb_epoch=5, batch_size=128, shuffle=True, validation_split= 0.02)
    History.append(history)

#model_path ='semi2_50ep.h5'
#autoencoder.save(model_path)
model_path ='Encoder.h5'
encoder.save(model_path)
